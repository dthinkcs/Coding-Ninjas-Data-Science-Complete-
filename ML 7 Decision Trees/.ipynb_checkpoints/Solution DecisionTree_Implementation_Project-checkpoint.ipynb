{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation\n",
    "* This code works only when:-\n",
    "  * The features of dataset are discrete\n",
    "  * The last column of dataset must be the label or class (output)\n",
    "  * Missing data is not allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw    y\n",
       "0  5.1  3.5  1.4  0.2  0.0\n",
       "1  4.9  3.0  1.4  0.2  0.0\n",
       "2  4.7  3.2  1.3  0.2  0.0\n",
       "3  4.6  3.1  1.5  0.2  0.0\n",
       "4  5.0  3.6  1.4  0.2  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(np.append(iris.data,iris.target.reshape(-1,1),axis = 1),columns = ['sl','sw','pl','pw','y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):       \n",
    "        return 1                  \n",
    "    elif (val < boundaries[1]):\n",
    "        return 2\n",
    "    elif (val < boundaries[2]):            ##here i have converted continuous data to discrete values of 1 ,2 ,3, 4 in each column\n",
    "                                                   #by <mean to be 2 , <(mean+min)/2 to be 1, <(mean+max)/2 to be 3 else to be 4                       \n",
    "        \n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sl_labeled'] = toLabel(df, 'sl')    #relabeling columns with discrete values and their header name\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw')\n",
    "df.head()\n",
    "c=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['sl_labeled','sw_labeled','pl_labeled',\"pw_labeled\",\"y\"]\n",
    "df=df.reindex(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['sl_labeled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_labeled</th>\n",
       "      <th>sw_labeled</th>\n",
       "      <th>pl_labeled</th>\n",
       "      <th>pw_labeled</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sl_labeled  sw_labeled  pl_labeled  pw_labeled    y\n",
       "0           2           3           1           1  0.0\n",
       "1           1           2           1           1  0.0\n",
       "2           1           3           1           1  0.0\n",
       "3           1           3           1           1  0.0\n",
       "4           1           3           1           1  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,0:4],df.iloc[:,4:], random_state = 1)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayant\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#converting feature columns and outputs in numpy array\n",
    "unused_features = list(df.columns)\n",
    "#unused_features.remove('y')\n",
    "xx = list(df.as_matrix(columns=unused_features))  ##numpy matrix of feature values\n",
    "\n",
    "y = np.array(df['y'])  ##numpy matrix of output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for calculaing the entropy for any dataset whether it may be Parent or children\n",
    "import math\n",
    "def calEntropy(dataSet):\n",
    "    entropy=0\n",
    "    labelList=[example[-1] for example in dataSet]\n",
    "    uniqueLabelSet=set(labelList) ## stores a particular value only once \n",
    "    labelCount={}\n",
    "    for label in labelList:\n",
    "        if label not in labelCount.keys():\n",
    "            labelCount[label]=0\n",
    "        labelCount[label]+=1\n",
    "    for label in uniqueLabelSet:\n",
    "        prob=float(labelCount[label])/len(dataSet)\n",
    "        entropy-=prob*math.log(prob,2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is just used for the split of dataset  according to a given feature\n",
    "def splitDataSet(dataSet,feature,value):\n",
    "    returnDataSet=[]\n",
    "    for sample in dataSet:\n",
    "        if sample[feature]==value:\n",
    "            reducedSample=np.concatenate((sample[:feature],sample[feature+1:]))\n",
    "            returnDataSet.append(reducedSample) #### Splitted dataset\n",
    "    return returnDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function decides the best feature to split upon using information gain\n",
    "def bestFeatureToSplit(dataSet):\n",
    "    featureNum=len(dataSet[0])-1 ## counts the total no. of features \n",
    "    \n",
    "    bestFeature=-1\n",
    "    bestInfoGain=0.0\n",
    "    baseEntropy=calEntropy(dataSet) ## calculates entropy for each incoming dataset\n",
    "    print('current Entropy is = %.16f' % baseEntropy)\n",
    "    if baseEntropy==0:                   ## Special check for pure nodes\n",
    "        print('Reached Leaf node')  ## and declaring them terminal node(leaf) thereafter\n",
    "    ## Calculating  the informatin gain by first calculating the entropy for each children \n",
    "    ## and then subtracting their weighted avg. from the parent( baseEntropy)\n",
    "    for feature in range(featureNum):\n",
    "            newEntropy=0\n",
    "            featureValue=[example[feature] for example in dataSet]\n",
    "            uniqueFeatureValue=set(featureValue) ## stores a particular value only once \n",
    "            for value in uniqueFeatureValue:\n",
    "                subDataSet=splitDataSet(dataSet,feature,value)\n",
    "                prob=float(len(subDataSet))/len(dataSet)\n",
    "                newEntropy+=prob*calEntropy(subDataSet)\n",
    "            infoGain=baseEntropy-newEntropy\n",
    "            if infoGain>bestInfoGain:\n",
    "                bestInfoGain=infoGain\n",
    "                bestFeature=feature\n",
    "    ## Finding the split information by calculating sort of internal entropy within the feature for each feature value \n",
    "    splitinfo=0\n",
    "    labelList=[example[bestFeature] for example in dataSet]\n",
    "    uniqueLabelSet=set(labelList)\n",
    "    labelCount={}\n",
    "    for label in labelList:\n",
    "        if label not in labelCount.keys():\n",
    "            labelCount[label]=0\n",
    "        labelCount[label]+=1\n",
    "    for label in uniqueLabelSet:\n",
    "        prob=float(labelCount[label])/len(dataSet)\n",
    "        splitinfo-=prob*math.log(prob,2)   \n",
    "        \n",
    "    gain_ratio=bestInfoGain/splitinfo## Finding the gain ratio\n",
    "    \n",
    "    #### Printing which feature is currently getting used for split with all the parameters calculated for the split\n",
    "    print('Splitting on feature %s with gain ratio %.16f'%(unused_features[bestFeature],gain_ratio))\n",
    "    print(\"\\n\")\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for calculating majority count for an impure node \n",
    "import operator\n",
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote]=0\n",
    "        classCount[vote]+=1\n",
    "    sortedClassCount=sorted(classCount,reverse=True)\n",
    "    return sortedClassCount\n",
    "## final output for an impure node = sortedClassCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level  0\n",
      "Count of 0.0  = 50\n",
      "Count of 1.0  = 50\n",
      "Count of 2.0  = 50\n",
      "current Entropy is = 1.5849625007211561\n",
      "Splitting on feature pw_labeled with gain ratio 0.6996382036222090\n",
      "\n",
      "\n",
      "Level  1\n",
      "Count of 0.0  = 50\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  1\n",
      "Count of 1.0  = 10\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  1\n",
      "Count of 1.0  = 40\n",
      "Count of 2.0  = 16\n",
      "current Entropy is = 0.8631205685666310\n",
      "Splitting on feature pl_labeled with gain ratio 0.4334099495621066\n",
      "\n",
      "\n",
      "Level  2\n",
      "Count of 1.0  = 1\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  2\n",
      "Count of 1.0  = 39\n",
      "Count of 2.0  = 8\n",
      "current Entropy is = 0.6581912658132185\n",
      "Splitting on feature sl_labeled with gain ratio 0.1267450377580933\n",
      "\n",
      "\n",
      "Level  3\n",
      "Count of 2.0  = 1\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  3\n",
      "Count of 1.0  = 14\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  3\n",
      "Count of 1.0  = 23\n",
      "Count of 2.0  = 7\n",
      "current Entropy is = 0.7837769474847009\n",
      "Splitting on feature sl_labeled with gain ratio 0.0709203640514888\n",
      "\n",
      "\n",
      "Level  4\n",
      "Count of 1.0  = 3\n",
      "Count of 2.0  = 1\n",
      "Level  4\n",
      "Count of 1.0  = 14\n",
      "Count of 2.0  = 6\n",
      "Level  4\n",
      "Count of 1.0  = 6\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  3\n",
      "Count of 1.0  = 2\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  2\n",
      "Count of 2.0  = 8\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "Level  1\n",
      "Count of 2.0  = 34\n",
      "Current Entropy is: 0.000000\n",
      "Reached leaf Node\n",
      "\n",
      "\n",
      "# Printing decision tree in form of nested dictionary retured by generateTree() function :\n",
      "\n",
      "{'pw_labeled': {1.0: 0.0, 2.0: 1.0, 3.0: {'pl_labeled': {2.0: 1.0, 3.0: {'sl_labeled': {1.0: 2.0, 2.0: 1.0, 3.0: {'sw_labeled': {1.0: [2.0, 1.0], 2.0: [2.0, 1.0], 3.0: 1.0}}, 4.0: 1.0}}, 4.0: 2.0}}, 4.0: 2.0}}\n"
     ]
    }
   ],
   "source": [
    "def generateTree(dataSet,label,level,olddata):\n",
    "    labelList_=[example[-1] for example in dataSet] ## label/output list for dataset \n",
    "    uniqueLabelSet_=set(labelList_) ## comprises of only uniquely identified labels \n",
    "    labelCount_={} ## Dictionary that keeps count(value) for each label(key)\n",
    "    for label_ in labelList_:\n",
    "        if label_ not in labelCount_.keys(): ## starts label count for already present label as well as \n",
    "            labelCount_[label_]=0            ## intializes count for the newly identified labels\n",
    "        labelCount_[label_]+=1\n",
    "        \n",
    "        \n",
    "   \n",
    "    ##### Printing the level number at which evaluation takes place ####### \n",
    "    if dataSet!=olddata:\n",
    "        level+=1\n",
    "        olddata=dataSet\n",
    "        print('Level ',level)\n",
    "    else:\n",
    "        print('Level ',level)\n",
    "    ###### Printing Over #######\n",
    "    \n",
    "    ##### printing the count of labels corresponding to each parent or child in present dataset #####           \n",
    "    for i in labelCount_:    \n",
    "        print('Count of %s  = %d'%(i,labelCount_[i]))\n",
    "        if (calEntropy(dataSet))==0: ## Special check whether or not the leaf node reached\n",
    "            print('Current Entropy is: %f'%calEntropy(dataSet))\n",
    "            print('Reached leaf Node',end='\\n\\n')        \n",
    "    ######## Printing over ###########\n",
    "    \n",
    "    \n",
    "    labelList=[example[-1] for example in dataSet] # creates list of the labels in present dataset\n",
    "    \n",
    "    ###### TERMINATION CONDITIONS for Recursion #####\n",
    "    if labelList.count(labelList[0])==len(labelList):  ## condition for checking if or not node is pure \n",
    "        return labelList[0] \n",
    "    \n",
    "    if len(dataSet[0])==1:            #### If the node isn't pure then we vote for the majority labels present in the dataset \n",
    "        return majorityCnt(labelList)\n",
    "    #### END of TERMINATION CONDITIONS #####\n",
    "    \n",
    "    bestFeature=bestFeatureToSplit(dataSet) ## calling the bestFeatureToSplit() to know the best feature to split upon\n",
    "    bestFeatureLabel=label[bestFeature]\n",
    "    DecisionTree={bestFeatureLabel:{}} #### Creating a nested dictionary containing our decision tree \n",
    "    ## For above dictionary :-\n",
    "    ## keys =features on which split has taken place at each step\n",
    "    ## Value=the corresponding output if the current node is a leaf otherwise another dictionary for next feature split\n",
    "    del(label[bestFeature]) #### Deleting the feature upon which split has already taken place\n",
    "    \n",
    "    ##### Starting the actual decision making by using best feature split ######\n",
    "    featureValues=[example[bestFeature] for example in dataSet]\n",
    "    uniqueFeatureValues=set(featureValues) ## stores a particular value only once \n",
    "    #print(uniqueFeatureValues)\n",
    "    for value in uniqueFeatureValues:\n",
    "        subDataSet=splitDataSet(dataSet,bestFeature,value)\n",
    "        subLabel=label[:]\n",
    "        DecisionTree[bestFeatureLabel][value]=generateTree(subDataSet,subLabel,level,olddata)##Recursion call for reduced dataset after split  \n",
    "    return DecisionTree\n",
    "DecisionTree=generateTree(xx,unused_features,0,xx)\n",
    "print()\n",
    "print('# Printing decision tree in form of nested dictionary retured by generateTree() function :',end='\\n\\n')\n",
    "print(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
